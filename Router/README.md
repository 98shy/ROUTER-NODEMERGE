# 2-Stage Soft-Gated, Uncertainty-Aware Multi-Agent Router

A sophisticated routing system for multi-agent problem-solving that adaptively selects relevant agents based on question semantics and uncertainty estimation.

## ğŸ¯ Overview

The Router implements a two-stage selection process:

### **Stage-0: Representation Generation**
- Generates structured summary using LLM (zero-shot, no reasoning)
- Creates mixed embedding: `v = Î±Â·Embed(q) + (1-Î±)Â·Embed(t)`
- Refines semantic signals without making judgments

### **Stage-1: Adaptive Soft Block Routing**
- Computes block relevance using cosine similarity
- Generates probability distribution with temperature-controlled softmax
- Measures uncertainty using normalized entropy
- Adapts coverage threshold based on uncertainty (more uncertain â†’ wider scope)
- Selects blocks using cumulative probability mass (**NO Top-K!**)

### **Stage-2: Adaptive Role Routing** âœ…
- Constructs candidate role set from selected blocks
- Computes role relevance and probability distribution
- Measures role-level uncertainty
- Adapts participation threshold (fewer/more agents based on uncertainty)
- Selects final agent set Aâ‚€ using cumulative probability mass

## ğŸ—ï¸ Architecture

```
Router/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ mmlu_config.yaml        # Configuration and hyperparameters (MMLU dataset)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ prototypes/             # Prototype embeddings
â”‚       â”œâ”€â”€ block_prototypes.npy
â”‚       â””â”€â”€ role_prototypes.npy
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ router.py               # Main Router class
â”‚   â”œâ”€â”€ stage0.py               # Representation generation
â”‚   â”œâ”€â”€ stage1.py               # Block routing
â”‚   â””â”€â”€ utils.py                # Utility functions
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_router.py          # Test suite
â”œâ”€â”€ mmlu/                       # MMLU dataset
â””â”€â”€ requirements.txt
```

## ğŸ“¦ Installation

```bash
# Install dependencies
conda activate router
pip install -r requirements.txt

# Or install specific packages
pip install numpy pyyaml sentence-transformers torch
```

## ğŸš€ Quick Start

```python
from src.router import Router

# Initialize router
router = Router(config_path="config/mmlu_config.yaml")

# Route a question
question = "What is the derivative of x^2 + 3x + 5?"
result = router.route(question)

# Access results with probabilities (cumulative coverage-based)
print(f"ğŸ“¦ Selected Blocks ({result['num_blocks']}):")
for block_id, prob in result['block_probabilities'].items():
    print(f"  â€¢ {block_id} â†’ p_B = {prob:.4f}")

print(f"\nğŸ‘¥ Selected Agents ({result['num_agents']}):")
for role_id, prob in result['role_probabilities'].items():
    print(f"  â€¢ {role_id} â†’ p_r = {prob:.4f}")

# Uncertainty and coverage info
print(f"\nğŸ“Š Uncertainty:")
print(f"  Block: {result['uncertainty']['block_uncertainty']:.4f}")
print(f"  Role:  {result['uncertainty']['role_uncertainty']:.4f}")
```

## ğŸ”§ Configuration

Key hyperparameters in `config/mmlu_config.yaml`:

### Stage-0
- `alpha`: Mixing weight for embeddings (default: 0.5)
- `embedding_model`: Sentence transformer model

### Stage-1 (Block Routing)
- `temperature_block`: Softmax temperature (default: 0.3)
- `rho_min`: Minimum coverage threshold (default: 0.60)
- `rho_max`: Maximum coverage threshold (default: 0.95)
- `tau`: Uncertainty threshold for adaptation (default: 0.5)
- `beta`: Sigmoid steepness (default: 8.0)

### Stage-2 (Role Routing)
- `temperature_role`: Softmax temperature (default: 0.3)
- `rho_min_role`: Minimum coverage threshold (default: 0.50)
- `rho_max_role`: Maximum coverage threshold (default: 0.90)
- `tau_role`: Uncertainty threshold for adaptation (default: 0.5)
- `beta_role`: Sigmoid steepness (default: 8.0)

## ğŸ§ª Testing

```bash
# Run test suite
cd Router
python tests/test_router.py
```

The test suite includes:
- Basic routing functionality
- Uncertainty variation analysis
- Coverage threshold adaptation

## ğŸ“Š Blocks and Roles

### Predefined Blocks
1. **MathLogic**: Mathematics, Logic, Statistics
2. **CS_Eng_Physics**: Computer Science, Engineering, Physics
3. **Bio_Med**: Biology, Medicine, Health Sciences
4. **Econ_Law_Social**: Economics, Law, Social Sciences
5. **Humanities**: History, Philosophy, Literature
6. **General_Meta**: General Knowledge, Meta-reasoning

### Roles per Block
Each block contains 3 specialized roles (18 roles total).

## ğŸ“ Key Features

### âœ… Uncertainty-Aware Adaptation
- Low uncertainty â†’ narrow scope (single-domain)
- High uncertainty â†’ wide scope (cross-domain)
- Smooth transition via sigmoid function

### âœ… NO Top-K Selection
- Uses cumulative probability mass instead of fixed K
- Adaptive number of blocks based on uncertainty
- More principled than arbitrary thresholds

### âœ… Temperature-Controlled Softmax
- Adjustable distribution sharpness
- Lower temperature â†’ more confident selection
- Higher temperature â†’ more exploratory

### âœ… Prototype-Based Similarity
- Fast cosine similarity computation
- Pre-computed prototype embeddings
- Scalable to large agent sets

## ğŸ“ˆ Example Outputs

### Low Uncertainty (Single-Domain)
```
Question: "Calculate the integral of x^2"

Stage-1 (Blocks):
  Block Uncertainty: 0.12
  Adaptive Coverage Threshold: 0.61
  Actual Coverage: 0.65
  
  Selected Blocks (1):
    â€¢ MathLogic â†’ p_B = 0.6520

Stage-2 (Roles):
  Role Uncertainty: 0.24
  Adaptive Coverage Threshold: 0.52
  Actual Coverage: 0.55
  
  Selected Agents (A_0): 2 agents
    1. Mathematician      â†’ p_r = 0.3850  (í•µì‹¬ ì—­í• )
    2. Statistician       â†’ p_r = 0.1650  (ë³´ì¡° ì—­í• )
  
  ğŸ’¡ Key: p_r represents each agent's relevance/contribution weight
```

### High Uncertainty (Cross-Domain)
```
Question: "Discuss AI ethics in healthcare from medical and philosophical perspectives"

Stage-1 (Blocks):
  Block Uncertainty: 0.78
  Adaptive Coverage Threshold: 0.92
  Actual Coverage: 0.95
  
  Selected Blocks (3):
    â€¢ Bio_Med         â†’ p_B = 0.4200
    â€¢ Humanities      â†’ p_B = 0.3500
    â€¢ General_Meta    â†’ p_B = 0.1800

Stage-2 (Roles):
  Role Uncertainty: 0.65
  Adaptive Coverage Threshold: 0.82
  Actual Coverage: 0.86
  
  Selected Agents (A_0): 7 agents
    1. Doctor                 â†’ p_r = 0.1850
    2. Philosopher            â†’ p_r = 0.1650
    3. Biologist              â†’ p_r = 0.1450
    4. Historian              â†’ p_r = 0.1250
    5. Generalist             â†’ p_r = 0.1100
    6. Critic                 â†’ p_r = 0.0950
    7. Common_Sense_Reasoner  â†’ p_r = 0.0750
  
  ğŸ’¡ High uncertainty â†’ More diverse agents needed for comprehensive coverage
```

## ğŸ”¬ Research Notes

### Adaptive Coverage Formula
```
Ï_B(Å©_B) = Ï_min + (Ï_max - Ï_min) Â· Ïƒ(Î²(Å©_B - Ï„))
```

where:
- `Å©_B`: Normalized entropy (uncertainty)
- `Ï_min, Ï_max`: Coverage bounds
- `Ï„`: Uncertainty threshold
- `Î²`: Transition steepness
- `Ïƒ`: Sigmoid function

### Cumulative Selection Algorithm
```python
1. Sort blocks by probability (descending)
2. Accumulate probability mass
3. Select prefix until mass â‰¥ threshold
4. Return selected blocks
```

## ğŸ› ï¸ Development

### Adding New Blocks/Roles
1. Edit `config/mmlu_config.yaml`
2. Add block definition and role mapping
3. Add prototype descriptions
4. Regenerate prototypes (will auto-generate on next run)

### Custom Embedding Models
Replace `embedding_model` in config with any sentence-transformers model:
- `all-mpnet-base-v2` (default, balanced)
- `all-MiniLM-L6-v2` (faster, smaller)
- `multi-qa-mpnet-base-dot-v1` (Q&A optimized)

### LLM Integration
Implement your LLM client in `router.py`:
```python
def _create_llm_client(self):
    # Replace MockLLMClient with real implementation
    # e.g., OpenAI, Anthropic, local models
    pass
```

## ğŸ“ TODOs

- [x] Implement Stage-2 (Role Selection) âœ…
- [x] Add real LLM client integration âœ…âœ… **NEW: OpenAI API integrated!**
- [ ] Add caching for embeddings
- [ ] Implement batch processing optimization
- [ ] Add visualization tools
- [ ] Create Jupyter notebook examples
- [ ] Add performance benchmarks
- [ ] MMLU evaluation pipeline
- [ ] Compare with baseline routing methods

## ğŸ“š Citation

If you use this router in your research, please cite:

```bibtex
@misc{router2024,
  title={2-Stage Soft-Gated, Uncertainty-Aware Multi-Agent Router},
  author={Your Name},
  year={2024}
}
```

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

Contributions welcome! Please feel free to submit a Pull Request.

---

**Status**: Full 2-Stage Router Complete! âœ…âœ…  
**Version**: 1.0.0  
**Last Updated**: 2024-01-14
