"""
Stage-0: Representation Generation
No judgment, only signal refinement
"""

import numpy as np
import json
import logging
from typing import Dict, Any, Tuple

logger = logging.getLogger(__name__)


class Stage0RepresentationGenerator:
    """
    Stage-0: Generate mixed representation v from question q
    
    v = α·Embed(q) + (1-α)·Embed(t)
    
    where t is structured summary generated by LLM
    """
    
    def __init__(
        self,
        embedding_model,
        llm_client,
        config: Dict[str, Any]
    ):
        """
        Args:
            embedding_model: Sentence embedding model (e.g., sentence-transformers)
            llm_client: LLM client for structured summary generation
            config: Configuration dict
        """
        self.embedding_model = embedding_model
        self.llm_client = llm_client
        self.config = config
        
        self.alpha = config['stage0']['alpha']
        self.summary_prompt_template = config['stage0']['summary_prompt']
        
        logger.info(f"Stage0 initialized with alpha={self.alpha}")
    
    def generate_structured_summary(self, question: str) -> Dict[str, Any]:
        """
        Generate structured summary using LLM (zero-shot, no reasoning)
        
        Output format:
        {
            "task_format": "...",
            "domain_hint": "...",
            "key_concepts": [...],
            "routing_summary": "..."
        }
        
        Args:
            question: Input question text
        
        Returns:
            Structured summary dict
        """
        # Format prompt
        prompt = self.summary_prompt_template.format(question=question)
        
        try:
            # Call LLM (implementation depends on LLM client)
            # Here we assume a generic interface
            response = self.llm_client.generate(prompt)
            
            # Parse JSON response
            summary = json.loads(response)
            
            # Validate required fields
            required_fields = ['task_format', 'domain_hint', 'key_concepts', 'routing_summary']
            for field in required_fields:
                if field not in summary:
                    logger.warning(f"Missing field '{field}' in LLM response, using empty value")
                    summary[field] = ""
            
            logger.info("Structured summary generated successfully")
            return summary
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            # Return empty summary on error
            return {
                "task_format": "",
                "domain_hint": "",
                "key_concepts": [],
                "routing_summary": ""
            }
        except Exception as e:
            logger.error(f"Error generating structured summary: {e}")
            return {
                "task_format": "",
                "domain_hint": "",
                "key_concepts": [],
                "routing_summary": ""
            }
    
    def summary_to_text(self, summary: Dict[str, Any]) -> str:
        """
        Convert structured summary to text for embedding
        
        Args:
            summary: Structured summary dict
        
        Returns:
            Text representation
        """
        # Simple concatenation
        parts = [
            f"Task format: {summary.get('task_format', '')}",
            f"Domain: {summary.get('domain_hint', '')}",
            f"Key concepts: {', '.join(summary.get('key_concepts', []))}",
            f"Summary: {summary.get('routing_summary', '')}"
        ]
        
        text = " | ".join(parts)
        return text
    
    def generate_representation(
        self,
        question: str,
        use_llm_summary: bool = True
    ) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        Generate mixed representation vector v
        
        v = α·Embed(q) + (1-α)·Embed(t)
        
        Args:
            question: Input question
            use_llm_summary: Whether to use LLM summary (if False, use only question)
        
        Returns:
            v: Mixed representation vector (d,)
            debug_info: Debug information dict
        """
        logger.info("=" * 60)
        logger.info("STAGE-0: Representation Generation")
        logger.info("=" * 60)
        
        # Embed question
        q_embedding = self.embedding_model.encode(question)
        logger.info(f"Question embedding shape: {q_embedding.shape}")
        
        if not use_llm_summary:
            logger.info("Skipping LLM summary (use_llm_summary=False)")
            v = q_embedding
            debug_info = {
                "question": question,
                "summary": None,
                "alpha": self.alpha,
                "used_llm": False
            }
            return v, debug_info
        
        # Generate structured summary
        summary = self.generate_structured_summary(question)
        logger.info(f"Structured summary: {json.dumps(summary, indent=2)}")
        
        # Convert summary to text and embed
        summary_text = self.summary_to_text(summary)
        t_embedding = self.embedding_model.encode(summary_text)
        logger.info(f"Summary embedding shape: {t_embedding.shape}")
        
        # Mix embeddings
        v = self.alpha * q_embedding + (1 - self.alpha) * t_embedding
        logger.info(f"Mixed representation shape: {v.shape}")
        logger.info(f"Mixing ratio: α={self.alpha} (question) + (1-α)={1-self.alpha} (summary)")
        
        # Debug info
        debug_info = {
            "question": question,
            "summary": summary,
            "summary_text": summary_text,
            "alpha": self.alpha,
            "used_llm": True,
            "q_embedding_norm": float(np.linalg.norm(q_embedding)),
            "t_embedding_norm": float(np.linalg.norm(t_embedding)),
            "v_norm": float(np.linalg.norm(v))
        }
        
        logger.info(f"Representation generated (norm={debug_info['v_norm']:.4f})")
        
        return v, debug_info
